{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO2RmqPv8OFN"
      },
      "source": [
        "# Decision Tree Lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-mwgOlV8OFO"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import arff\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lT6XRJX8OFP"
      },
      "source": [
        "## 1 Debug and Eval\n",
        "\n",
        "### 1.1 (5%) Debug\n",
        "\n",
        "- Train a DecisionTreeClassifier on the [Iris Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/iris.arff) using all default parameters.\n",
        "- If using Dataframes you may want to change the class values from bytecodes to strings with\n",
        "iris_df['class'] = iris_df['class'].str.decode('utf-8')\n",
        "\n",
        "Expected Accuracy = [1.0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJnPbTu48OFP",
        "outputId": "fabdbce9-9768-4669-a448-3ca00adc794c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "#Debug\n",
        "url = 'https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/iris.arff'\n",
        "urllib.request.urlretrieve(url, 'iris.arff')\n",
        "\n",
        "data, meta = arff.loadarff('iris.arff')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "y = y.str.decode('utf-8')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "print(dtc.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nFmU2-D8OFP"
      },
      "source": [
        "### 1.2 (5%) Evaluation\n",
        "\n",
        "- Train on the iris data set again but this time with max_depth = 3 and output the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icbLBt3e8OFQ",
        "outputId": "8dcec99c-c1f3-448a-cc76-6b5b347f1ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "dtc2 = DecisionTreeClassifier(max_depth=3)\n",
        "dtc2.fit(X_train, y_train)\n",
        "\n",
        "print(dtc2.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqMj9FGy8OFQ"
      },
      "source": [
        "#### Discussion\n",
        "What did you see? What were the differences in accuracy between the two trained models? How do you account for the differences or no differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnkAMlL_8OFQ"
      },
      "source": [
        "I didn't see any differences in accuracy between both the trained models. They came out as both 100% accuracy. I believe that because our dataset is so small and relatively simple (due to only 4 features). The tree only needs a few spilts in order to classify properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2yrrBCi8OFQ"
      },
      "source": [
        "## 2. Missing Values, N-fold CV, and Decision Tree Items  \n",
        "\n",
        "### 2.1 (15%) Handling missing values\n",
        "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
        "- This data set has missing data.  Create an extra feature value for each feature with missing data. For example, if the feature were color with possible values R, G, B, you would add a fourth value (e.g. U or ? for unknown).\n",
        "- Do not use a stopping criteria. Induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).\n",
        "- SKlearn does not allow nominal features, which initially seems odd. However, SKlearn uses the binary CART algorithm where a nominal data value like color is broken down into blue or not blue, red or not red, etc.  It is thus natural to just use one-hot encoding for each nominal feature.\n",
        "- Use an 80/20 train/test split.\n",
        "- Report the training and test set accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y0jNoLbq8OFQ",
        "outputId": "7ceedc85-71be-4657-a482-bfd3bc531a21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   handicapped-infants_missing  handicapped-infants_U  handicapped-infants_n  \\\n",
              "0                            0                      0                      1   \n",
              "1                            0                      0                      1   \n",
              "2                            1                      1                      0   \n",
              "3                            0                      0                      1   \n",
              "4                            0                      0                      0   \n",
              "\n",
              "   handicapped-infants_y  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      0  \n",
              "4                      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ed884f5-c76c-422a-a3e2-b5b81ebc24ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants_missing</th>\n",
              "      <th>handicapped-infants_U</th>\n",
              "      <th>handicapped-infants_n</th>\n",
              "      <th>handicapped-infants_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed884f5-c76c-422a-a3e2-b5b81ebc24ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ed884f5-c76c-422a-a3e2-b5b81ebc24ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ed884f5-c76c-422a-a3e2-b5b81ebc24ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-813d1dcd-4732-4fa1-9fc0-a064753f7bee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-813d1dcd-4732-4fa1-9fc0-a064753f7bee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-813d1dcd-4732-4fa1-9fc0-a064753f7bee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# print(dtc_vote\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"handicapped-infants_missing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"handicapped-infants_U\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"handicapped-infants_n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"handicapped-infants_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Learn Voting with missing values.\n",
        "url = 'https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff'\n",
        "urllib.request.urlretrieve(url, 'voting_with_missing.arff')\n",
        "\n",
        "data, meta = arff.loadarff('voting_with_missing.arff')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = df.map(lambda x: x.decode('utf-8'))\n",
        "\n",
        "df = df[['handicapped-infants']]\n",
        "# df.head()\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col + '_missing'] = (df[col] == '?').astype(int)\n",
        "\n",
        "\n",
        "df.replace('?', 'U', inplace=True)\n",
        "\n",
        "# X = df.drop(columns=['Class'])\n",
        "# y = df['Class']\n",
        "\n",
        "df_encoded = pd.get_dummies(df, dtype=int)\n",
        "df_encoded.head()\n",
        "\n",
        "# X = pd.get_dummies(X, dtype=int)\n",
        "\n",
        "# X_train_votes, X_test_votes,y_train_votes,y_test_votes = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# dtc_vote = DecisionTreeClassifier()\n",
        "# dtc_vote.fit(X_train_votes, y_train_votes)\n",
        "\n",
        "# print(dtc_vote.score(X_test_votes, y_test_votes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHqeUoqq8OFQ"
      },
      "source": [
        "#### Discussion\n",
        "Report on your accuracies and include explaining how the missing values were handled by your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCA_xY48OFR"
      },
      "source": [
        "I made sure to decode all the bytes into strings. Then, if there was a value with a question mark, I added a new feature `col_missing` for each feature if the value was missing (1 if missing, 0 if not missing) and then just replaced the ? with a \"U\". The final accuracies were 100% on the training set and 94.3% on the testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOBKsIJq8OFR"
      },
      "source": [
        "### 2.2 (15%)  N-fold Cross Validation\n",
        "- Learn the [Cars Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff) with the decision tree.\n",
        "- Create a table with the 10-fold cross validation accuracies and show the average predicted accuracy.\n",
        "- Try it again with 5-fold CV and create and show that table also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeSxGeh_8OFR",
        "outputId": "efe96619-f3ed-49f1-9d6a-0db4f674db01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average 10-Fold CV Accuracy: 0.8426\n",
            "Average 5-Fold CV Accuracy: 0.7373\n",
            "\n",
            "\n",
            "Table for 5-Fold CV:\n",
            " Fold  Accuracy\n",
            "    1  0.647399\n",
            "    2  0.731214\n",
            "    3  0.748555\n",
            "    4  0.753623\n",
            "    5  0.805797\n",
            "\n",
            "\n",
            "Table for 10-Fold CV:\n",
            " Fold  Accuracy\n",
            "    1  0.757225\n",
            "    2  0.780347\n",
            "    3  0.930636\n",
            "    4  0.676301\n",
            "    5  0.838150\n",
            "    6  0.924855\n",
            "    7  0.895954\n",
            "    8  0.861272\n",
            "    9  0.912791\n",
            "   10  0.848837\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff'\n",
        "urllib.request.urlretrieve(url, 'cars.arff')\n",
        "\n",
        "data, meta = arff.loadarff('cars.arff')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = df.map(lambda x: x.decode('utf-8'))\n",
        "\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "X = pd.get_dummies(X, dtype=int)\n",
        "\n",
        "dtc_cars = DecisionTreeClassifier()\n",
        "\n",
        "scores_for_10 = cross_val_score(dtc_cars, X, y, cv=10)\n",
        "scores_for_5 = cross_val_score(dtc_cars, X, y, cv=5)\n",
        "\n",
        "df_10 = pd.DataFrame(scores_for_10)\n",
        "df_5 = pd.DataFrame(scores_for_5)\n",
        "\n",
        "df_10 = pd.DataFrame({\"Fold\": list(range(1, 11)), \"Accuracy\": scores_for_10})\n",
        "df_5 = pd.DataFrame({\"Fold\": list(range(1, 6)), \"Accuracy\": scores_for_5})\n",
        "\n",
        "X_train_cars, X_test_cars, y_train_cars, y_test_cars = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "\n",
        "print(f\"Average 10-Fold CV Accuracy: {scores_for_10.mean():.4f}\")\n",
        "print(f\"Average 5-Fold CV Accuracy: {scores_for_5.mean():.4f}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Table for 5-Fold CV:\")\n",
        "print(df_5.to_string(index=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Table for 10-Fold CV:\")\n",
        "print(df_10.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOOlEn8a8OFR"
      },
      "source": [
        "#### Discussion\n",
        "Explain n-fold cross validation. Why do we do it? How is it useful? What does it reveal? Do we end up with a model? If so, which one?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwAauJtv8OFR"
      },
      "source": [
        "Let me start from the beginning, a pretty good practice is to maybe split the data 75% training and 25% testing, but that begs the question of which quarter should actually be the testing and which 3 quarters should actually be the training data. Well, with n-fold cross validation, we don't really have to worry about that! Like we did above, rather than worrying about which split would be best, cross validation will split them all, one at a time, and then output the averaged results. It reveals the best estimate for data that the model hasn't seen before. Using n-fold cross validation does not ouput a model (the training is done after) but just provides a better way than the classical 25/75 split to help us see how our model performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UPXMvSa8OFR"
      },
      "source": [
        "### 2.3 (10%) Decision Tree Intuition\n",
        "For each of the two problems above (Voting and Cars):\n",
        "- Print the full tree for each.  You may use tree.plot_tree(clf) or [another way](https://mljar.com/blog/visualize-decision-tree/) if you prefer.  tree.plot_tree has a number of parameters which you can try which let you print more informative trees which can help your discussion.\n",
        "- Train both again with max_depth = 2 and print these smaller trees and include them in your report.\n",
        "- Summarize in English what these 2 smaller decision trees have learned (i.e. look at the induced trees and describe what \"rules\" they discovered).\n",
        "- Compare your thoughts on important features with the attribute feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwayzBxO8OFR"
      },
      "outputs": [],
      "source": [
        "#Print induced trees for the voting and car data sets\n",
        "from sklearn import tree\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(dtc_vote, filled=True, feature_names=X_train_votes.columns, class_names=dtc_vote.classes_)\n",
        "plt.savefig(\"voting_full_tree.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(dtc_cars, filled=True, feature_names=X_train_cars.columns, class_names=dtc_cars.classes_)\n",
        "plt.savefig(\"cars_full_tree.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "dtc_vote_2 = DecisionTreeClassifier(max_depth=2)\n",
        "dtc_vote_2.fit(X_train_votes, y_train_votes)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(dtc_vote_2, filled=True, feature_names=X_train_votes.columns, class_names=dtc_vote_2.classes_)\n",
        "plt.savefig(\"voting_depth2_tree.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "dtc_cars_2 = DecisionTreeClassifier(max_depth=2)\n",
        "dtc_cars_2.fit(X_train_cars, y_train_cars)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(dtc_cars_2, filled=True, feature_names=X_train_cars.columns, class_names=dtc_cars_2.classes_)\n",
        "plt.savefig(\"cars_depth2_tree.png\", dpi=300)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"voting_full_tree.png\")\n",
        "files.download(\"cars_full_tree.png\")\n",
        "files.download(\"voting_depth2_tree.png\")\n",
        "files.download(\"cars_depth2_tree.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0TXLmJIpvICy",
        "outputId": "7f883cea-c0b4-4b3b-8907-fa7c7260407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60bcb26e-d62c-4885-ac60-b75b6fb43f89\", \"voting_full_tree.png\", 613363)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_faca32b9-5603-4fd0-a338-dc4539bdddd9\", \"cars_full_tree.png\", 697059)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c88d49cf-06e8-44c3-a626-350eea318469\", \"voting_depth2_tree.png\", 425784)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0cfd5f5d-497e-49c7-9f24-b5059f60f9ac\", \"cars_depth2_tree.png\", 521471)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW9mDQAb8OFR"
      },
      "source": [
        "#### Discussion\n",
        "Discuss what the Trees have learned on the 2 data sets (i.e. look at the induced trees and describe what \"rules\" they discovered). How do the important features you would think about correspond the the \"feature_importances_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zkc0opU8OFR"
      },
      "source": [
        "-- Voting Dataset --\n",
        "\n",
        "Based off the trees (both the depth2 and full) the tree found that `physician-fee-freeze_y` is the best feature for classifying if someone is a democrat or republican. It starts off with a `gini = 0.477` and then if you voted yes, you were most likely a democrat with a `gini = 0.039` which is pretty pure. If you voted no, you were most likely a republican with the `gini = 0.152` which is also pretty pure. From there is split the tree pretty well. There were some gini score of 0.0 as we went further down the tree, for instance, `export-administration-act-south-africa_y` the gini was 0 (pure) which means that if you voted yes, you were in fact a democrate, else republican.\n",
        "\n",
        "\n",
        "-- Cars Dataset --\n",
        "\n",
        "Based off the trees, the tree found that `safety_low` is the most important feature. If the car, wasn't safe, people were not going ot buy it (this makes sense to me). After safety the next most important feature is `persons_2` but found that if the car only seats 2 people, most didn't want to buy that car (this also makes sense as there is not many cars i.e convertible, sports cars, smart cars.. that only have two seats). From there, there was a mixture of gini scores and tons of branches since different people value different customary things when buys a car. But we know that saftey and number of passengers is a huge deal for anyone looking in purchasing a car.\n",
        "\n",
        "Thing to note: doing this all the way down to the max depth can lead to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ka0R6q98OFR"
      },
      "source": [
        "### 2.4 (5%) Other Parameters\n",
        "- For either of the data sets above experiment and discuss using a different split criterion (Compare Entropy and Log-loss with Gini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c9EQ43b8OFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e129359-ad50-4782-94d9-bbd1035c5cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gini score: 0.9425287356321839\n",
            "gini time: 0.007455587387084961\n",
            "\n",
            "\n",
            "entropy score: 0.9425287356321839\n",
            "entropy time: 0.004505634307861328\n",
            "\n",
            "\n",
            "log_loss score: 0.9425287356321839\n",
            "log_loss time: 0.0035316944122314453\n"
          ]
        }
      ],
      "source": [
        "# Experiment with criterion parameter\n",
        "import time\n",
        "\n",
        "time_start = time.time()\n",
        "dtc_gini = DecisionTreeClassifier(criterion='gini') # default\n",
        "dtc_gini.fit(X_train_votes, y_train_votes)\n",
        "time_end = time.time()\n",
        "print(f\"gini score: {dtc_gini.score(X_test_votes, y_test_votes)}\")\n",
        "print(f\"gini time: {time_end - time_start}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "time_start = time.time()\n",
        "dtc_entropy = DecisionTreeClassifier(criterion='entropy')\n",
        "dtc_entropy.fit(X_train_votes, y_train_votes)\n",
        "time_end = time.time()\n",
        "print(f\"entropy score: {dtc_entropy.score(X_test_votes, y_test_votes)}\")\n",
        "print(f\"entropy time: {time_end - time_start}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "time_start = time.time()\n",
        "dtc_log_loss = DecisionTreeClassifier(criterion='log_loss')\n",
        "dtc_log_loss.fit(X_train_votes, y_train_votes)\n",
        "time_end = time.time()\n",
        "print(f\"log_loss score: {dtc_log_loss.score(X_test_votes, y_test_votes)}\")\n",
        "print(f\"log_loss time: {time_end - time_start}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDYPnW3m8OFR"
      },
      "source": [
        "#### Discussion\n",
        "How does using different split criteria (entropy, log-loss, and gini) affect accuracy, tree structure, and feature importance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI1ozkoP8OFR"
      },
      "source": [
        "Based on running the code with these different split criteria, `log_loss` and `gini` were completely the same while `entropy` score produced a higher accuracy but not by a ton! Maybe if that dataset was larger, we would be seeing a bigger difference in scores... From a accuracy standpoint, `entropy` is preferred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYnfSjH68OFR"
      },
      "source": [
        "## 3 Overfit Avoidance with Decision Trees  \n",
        "\n",
        "Above, you found typical training and test set scores for the Cars data set when the tree is induced as far as it can go (until classes are pure or there are no more data or attributes to split on).  This usually leads to great training set scores but can potentially overfit and get lower accuracy on the test set.  You will now experiment with methods which can help avoid overfit and which could lead to better test set accuracy (though training set accuracy may decrease).  \n",
        "\n",
        "### 3.1 Smaller and Simpler Trees (20%)\n",
        "- tree_: [Read about](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py) the tree_ attribute with its sub attributes and methods allowing you to interact with your learned tree.  You don't have to do any specific task for this part.\n",
        "- Use an 80/20 train/test split for all experiments in this part and induce (learn/fit) the full tree for Cars.\n",
        "- For the fully induced tree print out\n",
        "    - Training set accuracy\n",
        "    - Test set accuracy\n",
        "    - Total number of nodes (clf.tree_.node_count)\n",
        "    - Maximum tree depth (clf.tree_.max_depth)\n",
        "- Experiment with the following parameters which lead to smaller and/or simpler trees which can help with overfit.  Try a few different values of each parameter and compare their train and test set accuracies and number of nodes and depth with the fully induced tree.  If you are not sure how parameters are actually working, print some trees to see their effect.  Due to the simplicity of the Cars data set you may not see as great of accuracy improvements as you would for cases where overfit is more prominent.  \n",
        "    - min_samples_leaf\n",
        "    - min_samples_split\n",
        "    - min_impurity_decrease\n",
        "- Try these parameters also, but note that they could lead to underfit\n",
        "    - max_depth\n",
        "    - max_leaf_nodes\n",
        "    - max_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwWjd7EL8OFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ac3dfb-a39c-4b6f-ab17-25b265fe194c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9595375722543352\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n"
          ]
        }
      ],
      "source": [
        "# Explore different overfit parameters\n",
        "url = 'https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff'\n",
        "urllib.request.urlretrieve(url, 'cars.arff')\n",
        "\n",
        "data, meta = arff.loadarff('cars.arff')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = df.map(lambda x: x.decode('utf-8'))\n",
        "\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "X = pd.get_dummies(X, dtype=int)\n",
        "\n",
        "dtc_cars = DecisionTreeClassifier()\n",
        "\n",
        "X_train_cars, X_test_cars, y_train_cars, y_test_cars = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "\n",
        "print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Params that could help with overfitting: min_samples_leaf, min_samples_split, min_impurity_decrease\n",
        "\n",
        "print(\" --------------------- Min Sample Leaf Values --------------------- \")\n",
        "min_samples_leaf_values = [1, 5, 10, 20]\n",
        "for min_samples_leaf in min_samples_leaf_values:\n",
        "    dtc_cars = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\" --------------------- Min Samples split values --------------------- \")\n",
        "min_samples_split_values = [2, 10, 20, 50]\n",
        "for min_samples_split in min_samples_split_values:\n",
        "    dtc_cars = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\" --------------------- Min Impurity Decrease Values --------------------- \")\n",
        "min_impurity_decrease_values = [0.0, 0.01, 0.02, 0.05]\n",
        "for min_impurity_decrease in min_impurity_decrease_values:\n",
        "    dtc_cars = DecisionTreeClassifier(min_impurity_decrease=min_impurity_decrease)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOpHDXq6YcPI",
        "outputId": "9d48ac8e-af6a-4b05-9fc8-ca35e350bb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --------------------- Min Sample Leaf Values --------------------- \n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9624277456647399\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9725036179450073\n",
            "Test set accuracy: 0.953757225433526\n",
            "Total number of nodes: 107\n",
            "Maximum tree depth: 11\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9392185238784371\n",
            "Test set accuracy: 0.9161849710982659\n",
            "Total number of nodes: 69\n",
            "Maximum tree depth: 10\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9117221418234442\n",
            "Test set accuracy: 0.9132947976878613\n",
            "Total number of nodes: 41\n",
            "Maximum tree depth: 9\n",
            "\n",
            "\n",
            " --------------------- Min Samples split values --------------------- \n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9566473988439307\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9761215629522432\n",
            "Test set accuracy: 0.9479768786127167\n",
            "Total number of nodes: 111\n",
            "Maximum tree depth: 11\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9522431259044862\n",
            "Test set accuracy: 0.9075144508670521\n",
            "Total number of nodes: 75\n",
            "Maximum tree depth: 11\n",
            "\n",
            "\n",
            "Training set accuracy: 0.902315484804631\n",
            "Test set accuracy: 0.8959537572254336\n",
            "Total number of nodes: 39\n",
            "Maximum tree depth: 9\n",
            "\n",
            "\n",
            " --------------------- Min Impurity Decrease Values --------------------- \n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9595375722543352\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            "Training set accuracy: 0.8321273516642547\n",
            "Test set accuracy: 0.8265895953757225\n",
            "Total number of nodes: 13\n",
            "Maximum tree depth: 6\n",
            "\n",
            "\n",
            "Training set accuracy: 0.7727930535455861\n",
            "Test set accuracy: 0.7976878612716763\n",
            "Total number of nodes: 5\n",
            "Maximum tree depth: 2\n",
            "\n",
            "\n",
            "Training set accuracy: 0.7727930535455861\n",
            "Test set accuracy: 0.7976878612716763\n",
            "Total number of nodes: 5\n",
            "Maximum tree depth: 2\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Params that could lead to undefit: max_depth, max_leaf_nodes, max_features\n",
        "\n",
        "print(\" --------------------- Max Depth --------------------- \")\n",
        "max_depth_list = [2,5,10,None]\n",
        "for max_depth in max_depth_list:\n",
        "    dtc_cars = DecisionTreeClassifier(max_depth=max_depth)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\" --------------------- Max Leaf Nodes --------------------- \")\n",
        "max_leaf_nodes_list = [2, 5, 10, 20, None]\n",
        "for max_leaf_nodes in max_leaf_nodes_list:\n",
        "    dtc_cars = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\" --------------------- Max Features --------------------- \")\n",
        "max_features_list = [None, 'sqrt', 'log2']\n",
        "for max_features in max_features_list:\n",
        "    dtc_cars = DecisionTreeClassifier(max_features=max_features)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4tkdU39W7qC",
        "outputId": "6b5ce96d-1a85-4d40-b779-cefa40450c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --------------------- Max Depth --------------------- \n",
            "Training set accuracy: 0.7727930535455861\n",
            "Test set accuracy: 0.7976878612716763\n",
            "Total number of nodes: 5\n",
            "Maximum tree depth: 2\n",
            "\n",
            "\n",
            "Training set accuracy: 0.8523878437047757\n",
            "Test set accuracy: 0.8670520231213873\n",
            "Total number of nodes: 19\n",
            "Maximum tree depth: 5\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9876989869753979\n",
            "Test set accuracy: 0.953757225433526\n",
            "Total number of nodes: 147\n",
            "Maximum tree depth: 10\n",
            "\n",
            "\n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9624277456647399\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            " --------------------- Max Leaf Nodes --------------------- \n",
            "Training set accuracy: 0.7054992764109985\n",
            "Test set accuracy: 0.6791907514450867\n",
            "Total number of nodes: 3\n",
            "Maximum tree depth: 1\n",
            "\n",
            "\n",
            "Training set accuracy: 0.8024602026049205\n",
            "Test set accuracy: 0.8179190751445087\n",
            "Total number of nodes: 9\n",
            "Maximum tree depth: 4\n",
            "\n",
            "\n",
            "Training set accuracy: 0.869753979739508\n",
            "Test set accuracy: 0.8988439306358381\n",
            "Total number of nodes: 19\n",
            "Maximum tree depth: 6\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9312590448625181\n",
            "Test set accuracy: 0.9421965317919075\n",
            "Total number of nodes: 39\n",
            "Maximum tree depth: 8\n",
            "\n",
            "\n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9624277456647399\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            " --------------------- Max Features --------------------- \n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9595375722543352\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.8815028901734104\n",
            "Total number of nodes: 461\n",
            "Maximum tree depth: 15\n",
            "\n",
            "\n",
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.8959537572254336\n",
            "Total number of nodes: 569\n",
            "Maximum tree depth: 15\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QstkBrVO8OFS"
      },
      "source": [
        "#### Discussion\n",
        "How did the methods used above help avoid overfit? How do you know? How did they affect accuracy (training and test) and tree structure? Which parameters helped the most with each dataset? How do you know?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njGny9u48OFS"
      },
      "source": [
        "The best thing to look for when seeing if a method has helped overfitting is that if the test and training accuracy are pretty close to eachother. We started out with at first with 100% train accuracy and 95% test accuracy which has some signs of overfitting. Based off, the biggest help in avoiding being overfit was `min_samples_split_values = 10`\n",
        "\n",
        "\n",
        "Training set accuracy: 0.9725036179450073\n",
        "Test set accuracy: 0.953757225433526\n",
        "Total number of nodes: 107\n",
        "Maximum tree depth: 11\n",
        "\n",
        "\n",
        "Also I did some underfitting with certain parameters, especially playing with max_leaf_nodes which is to be expected per the paragraph above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1QHXkxH8OFS"
      },
      "source": [
        "### 3.2 (10%) Tree Reduction\n",
        "Another approach to avoiding overfit is using pruning to reduce fully induced trees.  Induce the tree fully for Cars (no simplifying parameters such as max_depth).  Prune by setting the [ccp_alpha](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html#sphx-glr-auto-examples-tree-plot-cost-complexity-pruning-py) parameter to a positive value. This parameter controls how aggressive the pruning is. Try some small values (e.g. ,001, ,005, etc.) and try to find and report the value which works the best.  Make a table with at least 5 ccp_alpha values and for each value include\n",
        "- Training set accuracy (you chooses the size of the train/test split)\n",
        "- Test set accuracy\n",
        "- Total number of nodes (clf.tree_.node_count)\n",
        "- Maximum tree depth (clf.tree_.max_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBmg_tvO8OFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e012cf-205b-4536-b63d-4724dd9b26d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy: 1.0\n",
            "Test set accuracy: 0.9624277456647399\n",
            "Total number of nodes: 171\n",
            "Maximum tree depth: 13\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9869753979739508\n",
            "Test set accuracy: 0.9479768786127167\n",
            "Total number of nodes: 107\n",
            "Maximum tree depth: 12\n",
            "\n",
            "\n",
            "Training set accuracy: 0.9261939218523878\n",
            "Test set accuracy: 0.930635838150289\n",
            "Total number of nodes: 35\n",
            "Maximum tree depth: 8\n",
            "\n",
            "\n",
            "Training set accuracy: 0.8835021707670043\n",
            "Test set accuracy: 0.8901734104046243\n",
            "Total number of nodes: 25\n",
            "Maximum tree depth: 8\n",
            "\n",
            "\n",
            "Training set accuracy: 0.7727930535455861\n",
            "Test set accuracy: 0.7976878612716763\n",
            "Total number of nodes: 5\n",
            "Maximum tree depth: 2\n",
            "\n",
            "\n",
            "Training set accuracy: 0.7727930535455861\n",
            "Test set accuracy: 0.7976878612716763\n",
            "Total number of nodes: 5\n",
            "Maximum tree depth: 2\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pruning\n",
        "ccp_alpha_values = [0.000, 0.001, 0.005, 0.01, 0.02, 0.05]\n",
        "for ccp_alpha in ccp_alpha_values:\n",
        "    dtc_cars = DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
        "    dtc_cars.fit(X_train_cars, y_train_cars)\n",
        "    print(f\"Training set accuracy: {dtc_cars.score(X_train_cars, y_train_cars)}\")\n",
        "    print(f\"Test set accuracy: {dtc_cars.score(X_test_cars, y_test_cars)}\")\n",
        "    print(f\"Total number of nodes: {dtc_cars.tree_.node_count}\")\n",
        "    print(f\"Maximum tree depth: {dtc_cars.tree_.max_depth}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiud-EMa8OFS"
      },
      "source": [
        "#### Discussion\n",
        "How did the pruning parameter ccp_alpha affect accuracy and tree structure? How does that compare to the methods above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRP3YiQ8OFS"
      },
      "source": [
        "When we are keeping our `ccp_alpha` values very low, it is good and can see that our we are not overfitting. The best value is `0.001`. When we start to be too aggressive and are setting the `ccp_alpha` value higher (0.01+) that is when we see our model underfitting. The difference between pruning and explicting playing with the other params (like we did above) is that instead of setting various limits, through pruning, we allow the tree to grow into its full state and then \"cut off\" the branches that dont provide the dont provide the best decision info, which reduces impurity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzgXv6MH8OFS"
      },
      "source": [
        "## 4. Decision Tree Regression\n",
        "### 4.1 (15%) Learn a real-world regression data set of your choice (not already used in this or previous labs)\n",
        "- Report tree statistics (# of nodes, # of leaf nodes, max depth)\n",
        "- Report MAE on the training and test set (you choose the size of the train/test split)\n",
        "- Report the DT regressor score for the training and test set.  Note that for the DT regressor this score is the coefficient of determination. Google it if you are curious."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTwHO21qgI59",
        "outputId": "107546df-73e0-4a35-e72e-9f387a7224e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXtdws8U8OFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff477c5-0724-4c27-f8f8-4de2b496ddd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy: 0.9974848071427982\n",
            "Test set accuracy: 0.970320732829923\n",
            "MAE on training set: 0.13631958662944008\n",
            "MAE on test set: 0.8186558441558445\n",
            "Number of nodes: 903\n",
            "Number of leaves: 452\n",
            "Max depth: 10\n"
          ]
        }
      ],
      "source": [
        "#Learn regression data set\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "energy_efficiency = fetch_ucirepo(id=242)\n",
        "\n",
        "X = energy_efficiency.data.features\n",
        "y = energy_efficiency.data.targets\n",
        "\n",
        "# print(energy_efficiency.metadata)\n",
        "# print(energy_efficiency.variables)\n",
        "\n",
        "\n",
        "dtr = DecisionTreeRegressor(ccp_alpha=0.005)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "dtr.fit(X_train, y_train)\n",
        "\n",
        "train_score = dtr.score(X_train, y_train)\n",
        "test_score = dtr.score(X_test, y_test)\n",
        "mae_train = mean_absolute_error(y_train, dtr.predict(X_train))\n",
        "mae_test = mean_absolute_error(y_test, dtr.predict(X_test))\n",
        "\n",
        "print(f\"Training set accuracy: {train_score}\")\n",
        "print(f\"Test set accuracy: {test_score}\")\n",
        "print(f\"MAE on training set: {mae_train}\")\n",
        "print(f\"MAE on test set: {mae_test}\")\n",
        "\n",
        "\n",
        "num_nodes = dtr.tree_.node_count\n",
        "num_leaves = dtr.get_n_leaves()\n",
        "max_depth = dtr.tree_.max_depth\n",
        "\n",
        "print(f\"Number of nodes: {num_nodes}\")\n",
        "print(f\"Number of leaves: {num_leaves}\")\n",
        "print(f\"Max depth: {max_depth}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEyZJcER8OFS"
      },
      "source": [
        "#### Discussion\n",
        "Discuss your choice of dataset and regression feature. Also discuss the items listed above in 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTNsV_kY8OFS"
      },
      "source": [
        "I picked the Energy Efficiency Dataset which predicts the heating or cooling load of a building based on structural and design features.\n",
        "\n",
        "At first I didn't have any pruning which proved to be a serious mistake with a really deep tree with tons of nodes and leaves. I then set the `ccp_alpha=0.005` and was able to get 99% train acc while still having 97% test acc. I was fiddling with the other params like up above in Quesiton #3 but wasn't able to get better accuracy for both sets like I did with pruning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmWBdTAr8OFS"
      },
      "source": [
        "## 5. (Optional 15% extra credit) Code up your own C4.5 Decision Tree Learner\n",
        "Implement the C4.5 algorithm discussed in class and in the slides, NOT the CART algorithm.  Below is a scaffold you could use if you want. Requirements for this task:\n",
        "- Your model should support the methods shown in the example scaffold below.\n",
        "- Use standard information gain as your basic attribute evaluation metric.  Note that C4.5 would usually augment information gain with a mechanism to penalize statistically insignificant attribute splits to avoid overfit (e.g. early stopping, gain ratio, etc.), but you are not required to do that.\n",
        "- Include the ability to handle unknown attributes by making \"unknown\" a new attribute value when needed.\n",
        "- You do not need to handle real valued attributes.\n",
        "- It is a good idea to use simple data set (like the pizza homework), which you can check by hand, to test each detailed step of your algorithm to make sure it works correctly.\n",
        "- Run your algorithm on the voting data set above with unknown attributes and compare your results with CART."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3xJHoNU8OFT"
      },
      "source": [
        "Discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKAJTn7D8OFT"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
        "\n",
        "    def __init__(self,counts=None):\n",
        "        \"\"\" Initialize class with chosen hyperparameters.\n",
        "        Args:\n",
        "        Optional Args (Args we think will make your life easier):\n",
        "            counts: A list of Ints that tell you how many types of each feature there are\n",
        "        Example:\n",
        "            DT  = DTClassifier()\n",
        "            or\n",
        "            DT = DTClassifier(count = [2,3,2,2])\n",
        "            Dataset =\n",
        "            [[0,1,0,0],\n",
        "            [1,2,1,1],\n",
        "            [0,1,1,0],\n",
        "            [1,2,0,1],\n",
        "            [0,0,1,1]]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit the data; Make the Decision tree\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 1D numpy array with the training targets\n",
        "\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 1D numpy array of the targets\n",
        "        \"\"\"\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5IuHeCa8OFY"
      },
      "outputs": [],
      "source": [
        "# Optional Debugging Dataset - Pizza Homework\n",
        "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
        "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf8c9878be96b81c1c8fce57c4415443b48baf3df3953f8cea607d661f4cb93b"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}